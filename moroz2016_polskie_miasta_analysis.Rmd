---
title: "Лингвистические пакеты в R: падежные предпочтения польских городов"
author: "Г. Мороз, 21 октября 2016, [https://goo.gl/Wh0WUq](https://goo.gl/Wh0WUq)"
output:
  html_notebook: default
  github_document: default
---

### 0. Введение
[Национальный корпус польского языка](http://nkjp.pl/poliqarp/) --- вещь достаточно неудобная. Настройки в одном месте, выдача в другом, скачать можно только в html (хотя обещают, что можно и в Excel). Как было славно, если бы можно было сразу собирать в R выдачу и ее там анализировать?

### 1. API для польского корпуса
Для того, чтобы решить данную проблему я написал API (в этом мне немного помог **Даня Алексеевский**, спасибо!). Так что я написал на R достаточно неуклюжую, наверное, [функцию `pl.corpus`](https://github.com/agricolamz/lingcorpora/blob/master/pl.corpus.R).

```{r pl.corpus --- API для польского корпуса, eval=FALSE, collapse=FALSE, include=FALSE}
pl.corpus <- function(x, tag = F, n.results = 100, corpus = "nkjp300"){
  library(xml2)
  library(rvest)
  library(httr)
  
  if(length(x) != 1){
    warning('x must be of length 1. If you want a dataframe with different queries try \n do.call("rbind.data.frame", sapply(x, pl.corpus, simplify = F))')
  }
  # show tags?
  if(tag == T){
    tag.variable <- "slt"
  } else {tag.variable <- "s"}
  
  # set nkjp.pl settings
  settings <- httr::POST(url = "http://nkjp.pl/poliqarp/settings/",
                         body = list(
                           random_sample = "0",
                           random_sample_size = "50",
                           sort_column = "rm",
                           sort_type = "afronte",
                           sort_direction = "asc",
                           show_in_match = tag.variable,
                           show_in_context = tag.variable,
                           left_context_width = "10",
                           right_context_width = "10",
                           wide_context_width = "50",
                           results_per_page = as.character(n.results),
                           `next` = "/poliqarp/"))
  
  # get request data
  request <- httr::POST(url = "http://nkjp.pl/poliqarp/query/",
                        body = list(query = x, corpus = corpus),
                        set_cookies(domain = "#HttpOnly_nkjp.pl",
                                    flag = "FALSE",
                                    path = "/",
                                    secure = "FALSE",
                                    expiration = "<NA>",
                                    name = "sessionid",
                                    value = as.character(settings$cookies[7]))) # cookies from settings
  
  # get data
  my.url <- httr::GET(url = "http://nkjp.pl/poliqarp/nkjp300/query/",
                      set_cookies(domain = "#HttpOnly_nkjp.pl",
                                  flag = "FALSE",
                                  path = "/",
                                  secure = "FALSE",
                                  expiration = "<NA>",
                                  name = "sessionid",
                                  value = as.character(request$cookies[7]))) # cookies from request
  
  # check for errors
  xml2::read_html(my.url) %>% 
    html_nodes(".errorlist > li:nth-child(1)") %>%
    html_text() -> 
    errorlist
  
  if(length(errorlist) > 0){
    warning(errorlist)
  }
  
  # check for no result
  xml2::read_html(my.url) %>% 
    html_nodes(".query-results > p:nth-child(2)") %>%
    html_text() -> 
    number.results
  if(length(number.results) > 1){
    if(grepl(pattern = "Found 0 results", number.results)){
      warning(paste('No results were returned by the query "', x, '"', sep = ""))
    }}
  
  # get left part
  xml2::read_html(my.url) %>% 
    html_nodes("td:nth-child(2)") %>%
    html_text() -> 
    left.part
  left.part <- gsub("\\s+", " ", left.part) # clean data
  
  # get query word
  xml2::read_html(my.url) %>% 
    html_nodes("td:nth-child(3)") %>%
    html_text() -> 
    center.part
  center.part <- gsub("\\s+", " ", center.part) # clean data
  
  # get right part
  xml2::read_html(my.url) %>% 
    html_nodes("td:nth-child(4)") %>%
    html_text() -> 
    right.part
  right.part <- gsub("\\s+", " ", right.part) # clean data
  
  results <- data.frame(left.part, center.part, right.part, stringsAsFactors = F)
  return(results)}
```

Чтобы не заставлять читателя разбираться в коде, поясню, что в результате в вашем окружении появляется функция `pl.corpus` со следующими аргументами:

* `x` --- запрос (обязательный аргумент);
* `tag` --- логический вектор, отвечающий за то, нужны ли в выдачи морфологические теги или нет;
* `n.results` --- переменная отвечающая за максимальное количество примеров в выдаче
* `corpus` --- вектор, определяющий подкорпус, в котором следует искать (возможные значения: `"nkjp300"`, `"nkjp1800"`, `"nkjp1M"`, `"ipi250"`, `"ipi030"`, `"frequency-dictionary"`)

Приведу пример работы функции:
```{r использование pl.corpus 1, echo=TRUE, message=FALSE, warning=FALSE}
head(pl.corpus("witam"))
```

```{r использование pl.corpus 2, echo=TRUE, message=FALSE, warning=FALSE}
head(pl.corpus("An*a", tag = T))
```
```{r использование pl.corpus 3, echo=TRUE, message=FALSE, warning=FALSE}
head(pl.corpus("[base = 'witać']"))
```
Как видно из примеров, функция понимает самые разные запросы:

* простые
* регулярными выражениями
* Corpus Query Language CQL

### 2. Данные
Данные о польских городах я взял из [Википедии](https://pl.wikipedia.org/wiki/Miasta_w_Polsce_(statystyki)). Были выбраны все города с населением больше 35500.

```{r, echo=TRUE}
library(lingtypology)
miasta <- read.csv("https://goo.gl/1zZgOa")
map.feature(languages = "Polish",
            popup = miasta$town.names,
            latitude = miasta$lat,
            longitude = miasta$long,
            control = F)
```

Как видно из кода, для создания данной карты требуется написанный мной пакет [`lingtypology`](https://github.com/agricolamz/lingtypology/wiki). Данный пакет позволяет рисовать карты на основе названий языков, вставляет ссылки на данные языки в базе данных [Glottolog](http://glottolog.org/).

Для дальнейшего исследования следует построить список запросов, которые бы можно было вставить в функцию `pl.corpus`. Здесь таилось множество проблем, связанных с особенностью корпуса:

* в самом простом случае достаточно было лишь написать название города
    + `[base = 'Kraków']`
* иногда приходилось менять большую букву на маленькую
    + `[base = 'warszawa']`
* все города, содержащие дефис, следовало разделить на два отдельных слова
    + `[base = 'Bielsko'] [base = 'Biała']`
* некоторые города либо целиком, либо частично совпадали с какими-то польскими словами и так хранились в польском корпусе, в таком случае я требовал написания с большой буквы
    + `[base = 'rudy' & orth = 'Rud.*'] [base = 'Śląsk']`
* несколько городов пришлось выкинуть:
    + из-за совпадений (Chrzanów, Jarosław)
    + из-за ошибки в корпусе `Radomsko [radomsko:adv:pos]`, но `Radomska [radomski:adj:sg:nom:f:pos]` (Knurów, Radomsko)
В результате каждый запрос пришлось проверять, так что результат этой работы записан в базе:

```{r, echo=TRUE}
head(miasta$query)
```

После обработки функцией `pl.corpus` всех запросов получилась [база данных, состоящая из 99129 примеров](https://goo.gl/zu3aTC), полученных по шаблонному запросу:
```{r, echo=TRUE}
head(pl.corpus(miasta$query[42], tag = T, n.results = 1000))
```

### 3. Обработка данных
Для обработки данных я написал две функции `pl.base` и `pl.case`.
```{r, echo=TRUE}
pl.base <- function(x){
  out <- c()
  for(j in seq_along(x)) {
    if(grepl("\\[.*:", x[j])){
      out[j] <- unlist(strsplit(unlist(strsplit(x[j], "\\["))[2], "\\:"))[1]
    } else {
      warning(paste0('No tags were found in the query "', x, '"'))
    }}
  return(out)
}
```


```{r, echo=TRUE}
pl.case <- function(x){
  out <- c()
  for(j in seq_along(x)) {
    if(grepl("\\[.*:", x[j])){
      out[j] <- unlist(strsplit(x[j], "\\:"))[4]
    } else {
      warning(paste0('No tags were found in the query "', x, '"'))
    }}
  return(out)
}
```

Функция `pl.base` позволяет выделять основу:

```{r, echo=TRUE}
pl.base("Wrocławia [Wrocław:subst:sg:gen:m3]")
```

Функция `pl.сase` позволяет выделять падеж:

```{r, echo=TRUE}
pl.case("Wrocławia [Wrocław:subst:sg:gen:m3]")
```

Для дальнейшего анализа понадобиться пакет `data.table`, который позволяет работать с бальшими файлами и пакет `dtplyr`, который позволяет удобно обрабатывать данные. Необработанные данные, которые будут дальше анализироваться можно скачать [здесь](https://goo.gl/M3BT4l).
```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(data.table); library(dtplyr)
df <- fread("moroz2016_polskie_miasta_row_data.csv", header = T)
```

Создадим новый датафрейм с основами и падежом:
```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(tidyverse)
df %>% 
  mutate(base = pl.base(query)) %>% 
  mutate(case = pl.case(query)) %>% 
  select(base, case) %>% 
  group_by(base, case) %>% 
  summarise(number = n()) ->
  base.case
head(base.case)
```

Построим простой график:
```{r}
base.case %>% 
  ggplot(aes(case, number))+
  geom_bar(stat = "identity", position = "dodge", fill = "lightblue")+
  theme_bw()
```

Для дальнейшей работы необходмо соединить изначальную базу (в переменной `miasta`) и новые данные (в переменной `base.case`).

```{r}
base.case %>% 
  spread(case, number) ->
  base.case
head(base.case)
```

Теперь можно присоединить получившуюся таблицу к уже имеющейся, выкинув первый и последний столбец:
```{r}
miasta <- cbind.data.frame(miasta[-52,], base.case[-73,])[,-c(6, 14)]
head(miasta)
```

Надо отметить, что не по всем запросам в корпусе нашлась 1000 примеров, так что абсолютные значения количества падежных форм для каждого города сравнивать между собой несколько бессмысленно. Поэтому заменим все пропущенные значения (`NA`) на 0, посчитаем сумму абсолютных значений в каждой строчке, а потом переведем абсолютные значения количества падежей в доли.

```{r}
miasta[is.na(miasta)] <- 0

for(i in 1:nrow(miasta)){
miasta %>%
    select(6:12) %>%
    slice(i) %>% 
    sum() ->
  miasta$n[i]}

for(j in 1:nrow(miasta)){
  miasta %>%
    select(6:12) %>%
    slice(j) %>% 
    prop.table() ->
    miasta[j,6:12]}
head(miasta)
```
```{r, include=FALSE}
rm(i); rm(j)
```

В результате данных операций возникли некоторые неправильные значения `NaN`. Это связано с тем, что некоторые города в корпусе не распознаны должным образом и имеют один единственный тег `ign` (Zawiercie, Chojnice). Избавимся от данных строчек:

```{r}
miasta <- miasta[complete.cases(miasta),]
```

Теперь все данные (в итоге 116 городов) собраны воедино и можно приступать к анализу.

### 4. Анализ данных
Во-первых, конечно, хочется посмотреть, какие значения приимают получившиеся доли:
```{r}
miasta %>%
  gather(case, rate, acc:voc) ->
miasta.for.analysis
miasta.for.analysis_2 <- miasta.for.analysis[,-7]

miasta.for.analysis %>% 
  ggplot(aes(rate, fill = case))+
  geom_histogram(data = miasta.for.analysis_2, fill = "lightgrey", bins = 17)+
  geom_histogram(bins = 17)+
  facet_wrap(~case)+
  theme_bw()
```
Данный график трудно читать, так что я добавлю такое же, но с отлогарифмированными осями:

```{r}
miasta.for.analysis %>% 
  filter(rate > 0) %>% 
  ggplot(aes(rate, fill = case))+
  geom_histogram(data = miasta.for.analysis_2, fill = "lightgrey", bins = 17)+
  geom_histogram(bins = 17)+
  facet_wrap(~case)+
  theme_bw() +
  scale_y_log10()
```

Как следует читать данные графики? Серым цветом обозначена гистограмма^[Существует стандартная проблемма с гистограммой, связанная с трудностью формализовать выбор количества ячеек гистограммы. Существует несколько подходов, здесь я выбрал алгоритм из работы (Freedman, Diaconis 1981), согласно которому для исследуемых данных следует использовать 17 ячеек.] всей выборки долей, без учета падежа. Цветом же показано, какой вклад вносит каждый падеж в создание общей гистограммы. Исследуя данный график можно сделать два наблюдения:

* во-первых, падежи делятся на те, которые чаще имеют маленькую долю (acc, dat, inst, voc), и на те, которые чаще имеют долю в промежутке между 0.2 и 0.6 (gen, nom, loc);
* во-вторых, некоторые города имеют в именительном падеже очень высокую долю близкую к единице (что в свою очередь означает, что они почти не выступают в других падежах).

Первый факт достаточно легко объяснить тем, что в польском латив и элатив маркируется предлогами _do_ и _z_, управляющими родительным падежом, а эссив маркируется предлогом _w_, управляющий местным падежом. В целом есть множество разных значений, которые оказались вне данной сильно упрощенной схемы, однако в первом приближении такое объяснение принять можно.

Второй факт следует рассматреть отдельно. Вот список городов с высокой долей разных падежей:

* **gen:** Ostrów Wielkopolski, Siedlce
* **nom:** Ruda Śląska, Starogard Gdański, Zielona Góra, Kędzierzyn-Koźle, Tarnowskie Góry

Видимо, Siedlce, действительно представлены так в корпусе, а все остальные названия, видимо, неправильно обрабатывались морфологическим парсером. Избавляемся от них и строим графики заново:

```{r}
miasta %>% 
  gather(case, rate, acc:voc) %>% 
  filter(rate < 1) ->
  miasta.for.analysis
miasta.for.analysis_2 <- miasta.for.analysis[,-7]

miasta.for.analysis %>% 
  ggplot(aes(rate, fill = case))+
  geom_histogram(data = miasta.for.analysis_2, fill = "lightgrey", bins = 17)+
  geom_histogram(bins = 17)+
  facet_wrap(~case)+
  theme_bw()
```

И с отлогарифмированной осью:
```{r}
miasta.for.analysis %>% 
  filter(rate > 0) %>% 
  ggplot(aes(rate, fill = case))+
  geom_histogram(data = miasta.for.analysis_2, fill = "lightgrey", bins = 17)+
  geom_histogram(bins = 17)+
  facet_wrap(~case)+
  theme_bw() +
  scale_y_log10()
```

Может быть какой-то падеж коррелирует с количеством носителей? (Спасибо Ване Левину за этот вопрос).
```{r}
library(PerformanceAnalytics)
miasta %>% 
  select(5:12) %>%
  chart.Correlation(histogram = F, pch = ".")
```

Но все же в моих данных много размерностей, так что нужен способ их уменьшить. Так как данные числовые --- PCA. Давайте посмотрим на биплот (более крупный вариант доступен [здесь](https://goo.gl/BZCx8R)):

```{r}
library(ggfortify)
miasta.for.pca <- miasta[,6:12]
row.names(miasta.for.pca) <- miasta$town.names
autoplot(prcomp(miasta.for.pca),
         shape = F,
         label = T,
         label.size = 2,
         loadings = T,
         loadings.label = T)+
  theme_bw()
```

В догонку к графику, обычно принято показывать, какой вклад вносят компоненты в объяснение изменчивости:

```{r}
summary(prcomp(miasta.for.pca))
```
Как видно из summary, уже первые две компоненты объясняют 92 процента всей изменчивости исходных данных.

Что нам говорит график биплот? Видимо, в наших данных нет четких кластеров, т. е. есть ядро и несколько переферий: с одной стороны видны Tarnowskie Góry и т. п., которые имеют максимальную долю в именительном падеже, с другой стороны Ostrów Wielkopolski, который имеет максимальную долю в родительном падеже, с третьей стороны Bydgoszcz, имеющий максимум в местном падеже. Переферия городов, имеющих много форм именительного и родительного падежа, но совсем мало местного падежа, кажется чуть больше.

Создадим переменную, отличающую города по степени переферичности.
```{r}
miasta$core <- NA
miasta$core[-c(8, 42, 33, 94, 4, 13,22, 2, 46, 97, 31, 38, 39, 99, 77, 29, 56, 7, 73, 27, 64, 51, 63, 16, 20, 45, 112, 90, 3, 18, 114, 88, 72)] <- "core"
miasta$core[c(8, 42, 33, 94, 4, 13,22,2, 46, 97,31, 39, 38, 99, 77, 29, 56, 7, 73, 27, 64, 51, 63, 16, 20, 45, 112, 90, 3, 18, 114, 88, 72)] <- "periphery"
autoplot(prcomp(miasta.for.pca), data = miasta, colour = 'core',  shape = FALSE, label.size = 3)+
  theme_bw()
```

Видимо, выделенная черта, не связанна с географией.
```{r}
set.seed(11)
map.feature(languages = "Polish",
            features = miasta$core,
            popup = miasta$town.names,
            latitude = miasta$lat,
            longitude = miasta$long)
```

Видимо, выделенная черта, не связанна с количеством населения.

```{r}
miasta %>%
  ggplot(aes(core, ludnosc_.31.12.2014., label = town.names))+
  geom_violin(fill = "lightblue")+
  geom_jitter(width = 0.3)+
  theme_bw()+
  ylab("количество человек (31.12.2014)")
```

